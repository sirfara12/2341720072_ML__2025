{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNApq/EM8yt8LQP0CQfeYWC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"1G8wDfhGjF1T"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["### Praktikum 2"],"metadata":{"id":"cm-B7RJquogW"}},{"cell_type":"code","source":["from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import OneHotEncoder\n","import tensorflow as tf\n","\n","# Load dataset\n","iris = load_iris()\n","X = iris.data\n","y = iris.target.reshape(-1, 1)\n","\n","# One-hot encoding\n","encoder = OneHotEncoder(sparse_output=False)\n","y = encoder.fit_transform(y)\n","\n","# Split data\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n","\n","# Bangun model\n","model = tf.keras.Sequential([\n","    tf.keras.layers.Dense(10, activation='relu', input_shape=(4,)),\n","    tf.keras.layers.Dense(8, activation='relu'),\n","    tf.keras.layers.Dense(3, activation='softmax')\n","])\n","\n","# Kompilasi\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Latih model\n","model.fit(X_train, y_train, epochs=50, batch_size=8)\n","\n","# Evaluasi\n","loss, acc = model.evaluate(X_test, y_test)\n","print(f\"Akurasi: {acc}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uJ_1OkwWukXD","executionInfo":{"status":"ok","timestamp":1763633597300,"user_tz":-420,"elapsed":5388,"user":{"displayName":"Sirf Aratih","userId":"14045773566137743177"}},"outputId":"69ebefc3-b1ce-4cac-f6f3-a2420c1faac4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.3676 - loss: 1.1713\n","Epoch 2/50\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3493 - loss: 1.1510 \n","Epoch 3/50\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3049 - loss: 1.1291 \n","Epoch 4/50\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3601 - loss: 1.0853 \n","Epoch 5/50\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3646 - loss: 1.0724 \n","Epoch 6/50\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3848 - loss: 1.0762 \n","Epoch 7/50\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5379 - loss: 1.0469 \n","Epoch 8/50\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4568 - loss: 1.0737 \n","Epoch 9/50\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5661 - loss: 1.0284 \n","Epoch 10/50\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5126 - loss: 1.0339 \n","Epoch 11/50\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4134 - loss: 1.0061 \n","Epoch 12/50\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3624 - loss: 1.0041 \n","Epoch 13/50\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3689 - loss: 0.9867 \n","Epoch 14/50\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3081 - loss: 0.9838 \n","Epoch 15/50\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3600 - loss: 0.9620 \n","Epoch 16/50\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4624 - loss: 0.9251 \n","Epoch 17/50\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5725 - loss: 0.9277 \n","Epoch 18/50\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7033 - loss: 0.9008 \n","Epoch 19/50\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7105 - loss: 0.8698 \n","Epoch 20/50\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7037 - loss: 0.8570 \n","Epoch 21/50\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7183 - loss: 0.8279 \n","Epoch 22/50\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7275 - loss: 0.8161 \n","Epoch 23/50\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6986 - loss: 0.8105 \n","Epoch 24/50\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6606 - loss: 0.7943 \n","Epoch 25/50\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6896 - loss: 0.7847 \n","Epoch 26/50\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7027 - loss: 0.7703 \n","Epoch 27/50\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7700 - loss: 0.6986 \n","Epoch 28/50\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7192 - loss: 0.7160 \n","Epoch 29/50\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7423 - loss: 0.6899 \n","Epoch 30/50\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8142 - loss: 0.6380\n","Epoch 31/50\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8043 - loss: 0.6251 \n","Epoch 32/50\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8504 - loss: 0.6313 \n","Epoch 33/50\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8212 - loss: 0.5794 \n","Epoch 34/50\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8283 - loss: 0.5582 \n","Epoch 35/50\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8514 - loss: 0.5585 \n","Epoch 36/50\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8579 - loss: 0.5400 \n","Epoch 37/50\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8523 - loss: 0.5294 \n","Epoch 38/50\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8285 - loss: 0.5359 \n","Epoch 39/50\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8877 - loss: 0.4827 \n","Epoch 40/50\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9108 - loss: 0.4853 \n","Epoch 41/50\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8920 - loss: 0.4622 \n","Epoch 42/50\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9324 - loss: 0.4235 \n","Epoch 43/50\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9407 - loss: 0.4412 \n","Epoch 44/50\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9373 - loss: 0.4229 \n","Epoch 45/50\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9538 - loss: 0.4335 \n","Epoch 46/50\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9716 - loss: 0.4165 \n","Epoch 47/50\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9132 - loss: 0.3949 \n","Epoch 48/50\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9729 - loss: 0.3555 \n","Epoch 49/50\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9684 - loss: 0.3452 \n","Epoch 50/50\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9595 - loss: 0.3799 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.9333 - loss: 0.3496\n","Akurasi: 0.9333333373069763\n"]}]},{"cell_type":"markdown","source":["### Tugas 2"],"metadata":{"id":"7EWTdRMNw7-x"}},{"cell_type":"code","source":["# ==========================\n","# SETUP DATASET IRIS\n","# ==========================\n","\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import OneHotEncoder\n","import tensorflow as tf\n","import numpy as np\n","\n","# Load dataset\n","iris = load_iris()\n","X = iris.data\n","y = iris.target.reshape(-1, 1)\n","\n","# One-hot encoding\n","encoder = OneHotEncoder(sparse_output=False)\n","y = encoder.fit_transform(y)\n","\n","# Train-test split\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, random_state=42\n",")\n","print(\"Jumlah data train:\", X_train.shape[0])\n","print(\"Jumlah data test :\", X_test.shape[0])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kKcmvmZjus-M","executionInfo":{"status":"ok","timestamp":1763633905615,"user_tz":-420,"elapsed":26,"user":{"displayName":"Sirf Aratih","userId":"14045773566137743177"}},"outputId":"d6247fdb-bcf5-4012-9aee-74c874b12d51"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Jumlah data train: 120\n","Jumlah data test : 30\n"]}]},{"cell_type":"code","source":["# bandingkan\n","\n","# ==========================\n","# FUNGSI MEMBANGUN & MELATIH MODEL\n","# ==========================\n","\n","def train_model(neuron1=10, neuron2=8):\n","    model = tf.keras.Sequential([\n","        tf.keras.layers.Dense(neuron1, activation='relu', input_shape=(4,)),\n","        tf.keras.layers.Dense(neuron2, activation='relu'),\n","        tf.keras.layers.Dense(3, activation='softmax')\n","    ])\n","\n","    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","    history = model.fit(X_train, y_train, epochs=50, batch_size=8, verbose=0)\n","    loss, acc = model.evaluate(X_test, y_test, verbose=0)\n","\n","    return acc, loss\n","\n"],"metadata":{"id":"izZY64CvxEhc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["configs = [\n","    (4, 4),\n","    (8, 4),\n","    (10, 8),  # konfigurasi awal\n","    (16, 8),\n","    (32, 16),\n","]\n","\n","print(\"Perbandingan Akurasi berdasarkan jumlah neuron:\")\n","print(\"===============================================\")\n","for n1, n2 in configs:\n","    acc, loss = train_model(n1, n2)\n","    print(f\"Hidden Layer = [{n1}, {n2}]  --> Akurasi = {acc:.4f}, Loss = {loss:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HKUiIXHKxlrh","executionInfo":{"status":"ok","timestamp":1763634002727,"user_tz":-420,"elapsed":20952,"user":{"displayName":"Sirf Aratih","userId":"14045773566137743177"}},"outputId":"3df9a82f-f4c3-4534-b948-dd78e984ea4c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Perbandingan Akurasi berdasarkan jumlah neuron:\n","===============================================\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Hidden Layer = [4, 4]  --> Akurasi = 0.5000, Loss = 1.0734\n","Hidden Layer = [8, 4]  --> Akurasi = 0.8000, Loss = 0.4688\n","Hidden Layer = [10, 8]  --> Akurasi = 1.0000, Loss = 0.2489\n","Hidden Layer = [16, 8]  --> Akurasi = 1.0000, Loss = 0.1374\n","Hidden Layer = [32, 16]  --> Akurasi = 1.0000, Loss = 0.0873\n"]}]},{"cell_type":"markdown","source":["## Tugas 3"],"metadata":{"id":"0zIWDL-Vxwp-"}},{"cell_type":"code","source":["# ==========================\n","# BANDINKAN RELU vs SIGMOID\n","# ==========================\n","\n","def train_activation(activation='relu'):\n","    model = tf.keras.Sequential([\n","        tf.keras.layers.Dense(10, activation=activation, input_shape=(4,)),\n","        tf.keras.layers.Dense(8, activation=activation),\n","        tf.keras.layers.Dense(3, activation='softmax')\n","    ])\n","\n","    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","    history = model.fit(X_train, y_train, epochs=50, batch_size=8, verbose=0)\n","\n","    loss, acc = model.evaluate(X_test, y_test, verbose=0)\n","    return acc, loss\n","\n","relu_acc, relu_loss = train_activation('relu')\n","sig_acc, sig_loss = train_activation('sigmoid')\n","\n","print(\"\\n=== Perbandingan Aktivasi ===\")\n","print(f\"ReLU     -> Akurasi: {relu_acc:.4f}, Loss: {relu_loss:.4f}\")\n","print(f\"Sigmoid  -> Akurasi: {sig_acc:.4f}, Loss: {sig_loss:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o9m9AOI-xuf3","executionInfo":{"status":"ok","timestamp":1763634015867,"user_tz":-420,"elapsed":6766,"user":{"displayName":"Sirf Aratih","userId":"14045773566137743177"}},"outputId":"903b0695-8313-4cb9-9572-4aad493ffa24"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== Perbandingan Aktivasi ===\n","ReLU     -> Akurasi: 0.9667, Loss: 0.2235\n","Sigmoid  -> Akurasi: 0.8000, Loss: 0.6350\n"]}]},{"cell_type":"markdown","source":["Hasil menunjukkan bahwa ReLU menghasilkan performa yang lebih baik dibandingkan Sigmoid, ditunjukkan oleh akurasi yang lebih tinggi dan loss yang lebih rendah.\n","Hal ini disebabkan karena ReLU tidak mengalami vanishing gradient, sehingga proses pembelajaran lebih stabil dan efektif pada hidden layer.\n","Sebaliknya, fungsi aktivasi Sigmoid memiliki kecenderungan menghasilkan gradien yang kecil, sehingga menyebabkan proses pelatihan lebih lambat dan performa model menurun."],"metadata":{"id":"uvv1g8PHyVVq"}}]}