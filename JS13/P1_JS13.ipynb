{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPtrOvoUb0XDHORLnPVqdNP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"sI3-7za_io5-"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["## Praktikum 1"],"metadata":{"id":"ark_Rt2jl5eu"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ENjJ_j07loYB","executionInfo":{"status":"ok","timestamp":1763630913288,"user_tz":-420,"elapsed":560,"user":{"displayName":"Sirf Aratih","userId":"14045773566137743177"}},"outputId":"819c6882-29b2-4526-940a-51416bdea3c6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0, Loss: 0.34034549075263576\n","Epoch 1000, Loss: 0.2437713953449532\n","Epoch 2000, Loss: 0.20918566389779106\n","Epoch 3000, Loss: 0.17117296887896127\n","Epoch 4000, Loss: 0.14881853037025103\n","Epoch 5000, Loss: 0.13872782184928545\n","Epoch 6000, Loss: 0.13408766372140798\n","Epoch 7000, Loss: 0.13162420276146589\n","Epoch 8000, Loss: 0.13014779743850763\n","Epoch 9000, Loss: 0.12918081743545592\n","Prediksi:\n","[[0.05299412]\n"," [0.49921446]\n"," [0.94045352]\n"," [0.50683498]]\n"]}],"source":["import numpy as np\n","\n","# Dataset XOR\n","X = np.array([[0,0],[0,1],[1,0],[1,1]])\n","y = np.array([[0],[1],[1],[0]])\n","\n","# Parameter\n","input_size = 2\n","hidden_size = 2\n","output_size = 1\n","lr = 0.1\n","\n","# Inisialisasi bobot\n","W1 = np.random.randn(input_size, hidden_size)\n","b1 = np.zeros((1, hidden_size))\n","W2 = np.random.randn(hidden_size, output_size)\n","b2 = np.zeros((1, output_size))\n","\n","# Fungsi aktivasi\n","def sigmoid(x):\n","    return 1 / (1 + np.exp(-x))\n","\n","def sigmoid_derivative(x):\n","    return x * (1 - x)\n","\n","# Training\n","for epoch in range(10000):\n","    # Forward pass\n","    z1 = np.dot(X, W1) + b1\n","    a1 = sigmoid(z1)\n","    z2 = np.dot(a1, W2) + b2\n","    a2 = sigmoid(z2)\n","\n","    # Hitung error\n","    error = y - a2\n","\n","    # Backpropagation\n","    d_a2 = error * sigmoid_derivative(a2)\n","    d_W2 = np.dot(a1.T, d_a2)\n","    d_b2 = np.sum(d_a2, axis=0, keepdims=True)\n","\n","    d_a1 = np.dot(d_a2, W2.T) * sigmoid_derivative(a1)\n","    d_W1 = np.dot(X.T, d_a1)\n","    d_b1 = np.sum(d_a1, axis=0, keepdims=True)\n","\n","    # Update bobot\n","    W1 += lr * d_W1\n","    b1 += lr * d_b1\n","    W2 += lr * d_W2\n","    b2 += lr * d_b2\n","\n","    if epoch % 1000 == 0:\n","        loss = np.mean(np.square(error))\n","        print(f\"Epoch {epoch}, Loss: {loss}\")\n","\n","# Output akhir\n","print(\"Prediksi:\")\n","print(a2)"]},{"cell_type":"markdown","source":["Tugas 1:\n","\n","Ubah jumlah neuron hidden layer menjadi 3.\n","\n"],"metadata":{"id":"UvsJWYR3mBD6"}},{"cell_type":"code","source":["import numpy as np\n","\n","# Dataset XOR\n","X = np.array([[0,0],[0,1],[1,0],[1,1]])\n","y = np.array([[0],[1],[1],[0]])\n","\n","# Parameter\n","input_size = 2\n","hidden_size = 3   # â‡ DIUBAH\n","output_size = 1\n","lr = 0.1\n","\n","# Inisialisasi bobot\n","W1 = np.random.randn(input_size, hidden_size)\n","b1 = np.zeros((1, hidden_size))\n","W2 = np.random.randn(hidden_size, output_size)\n","b2 = np.zeros((1, output_size))\n","\n","# Fungsi aktivasi sigmoid\n","def sigmoid(x):\n","    return 1 / (1 + np.exp(-x))\n","\n","def sigmoid_derivative(x):\n","    return x * (1 - x)\n","\n","# Training\n","for epoch in range(10000):\n","    # Forward pass\n","    z1 = np.dot(X, W1) + b1\n","    a1 = sigmoid(z1)\n","    z2 = np.dot(a1, W2) + b2\n","    a2 = sigmoid(z2)\n","\n","    # Hitung error\n","    error = y - a2\n","\n","    # Backpropagation\n","    d_a2 = error * sigmoid_derivative(a2)\n","    d_W2 = np.dot(a1.T, d_a2)\n","    d_b2 = np.sum(d_a2, axis=0, keepdims=True)\n","\n","    d_a1 = np.dot(d_a2, W2.T) * sigmoid_derivative(a1)\n","    d_W1 = np.dot(X.T, d_a1)\n","    d_b1 = np.sum(d_a1, axis=0, keepdims=True)\n","\n","    # Update bobot\n","    W1 += lr * d_W1\n","    b1 += lr * d_b1\n","    W2 += lr * d_W2\n","    b2 += lr * d_b2\n","\n","    if epoch % 1000 == 0:\n","        loss = np.mean(np.square(error))\n","        print(f\"Epoch {epoch}, Loss: {loss}\")\n","\n","print(\"Prediksi:\")\n","print(a2)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IiIwBOJGl_tq","executionInfo":{"status":"ok","timestamp":1763631416865,"user_tz":-420,"elapsed":2005,"user":{"displayName":"Sirf Aratih","userId":"14045773566137743177"}},"outputId":"c952bf91-d5df-4d66-bb1f-d6ecd67eed33"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0, Loss: 0.30059460967466545\n","Epoch 1000, Loss: 0.18703853252554775\n","Epoch 2000, Loss: 0.1028755860751508\n","Epoch 3000, Loss: 0.032596409787636504\n","Epoch 4000, Loss: 0.013791166485820468\n","Epoch 5000, Loss: 0.007929291115550975\n","Epoch 6000, Loss: 0.005362447429742767\n","Epoch 7000, Loss: 0.003979801207943299\n","Epoch 8000, Loss: 0.003132656525926896\n","Epoch 9000, Loss: 0.002566915213216369\n","Prediksi:\n","[[0.04140219]\n"," [0.95619755]\n"," [0.9560441 ]\n"," [0.05565509]]\n"]}]},{"cell_type":"markdown","source":["Bnadingkan hasil loss dengan konfigurasi awal\n"],"metadata":{"id":"sTsKwaUAoHkM"}},{"cell_type":"code","source":["import numpy as np\n","\n","# Dataset XOR\n","X = np.array([[0,0],[0,1],[1,0],[1,1]])\n","y = np.array([[0],[1],[1],[0]])\n","\n","\n","# =====================================================\n","# Fungsi Aktivasi\n","# =====================================================\n","\n","def sigmoid(x):\n","    return 1 / (1 + np.exp(-x))\n","\n","def sigmoid_derivative(x):\n","    return x * (1 - x)\n","\n","def relu(x):\n","    return np.maximum(0, x)\n","\n","def relu_derivative(x):\n","    return (x > 0).astype(float)\n","\n","\n","# =====================================================\n","# Fungsi Training Neural Network (dinamis)\n","# =====================================================\n","def train_nn(hidden_size=2, activation='sigmoid', epochs=10000, lr=0.1):\n","    input_size = 2\n","    output_size = 1\n","\n","    # Inisialisasi bobot\n","    W1 = np.random.randn(input_size, hidden_size)\n","    b1 = np.zeros((1, hidden_size))\n","    W2 = np.random.randn(hidden_size, output_size)\n","    b2 = np.zeros((1, output_size))\n","\n","    for epoch in range(epochs):\n","\n","        # Forward\n","        z1 = np.dot(X, W1) + b1\n","\n","        if activation == 'sigmoid':\n","            a1 = sigmoid(z1)\n","            d_act = sigmoid_derivative\n","        else:\n","            a1 = relu(z1)\n","            d_act = relu_derivative\n","\n","        z2 = np.dot(a1, W2) + b2\n","        a2 = sigmoid(z2)\n","\n","        error = y - a2\n","\n","        # Backprop\n","        d_a2 = error * sigmoid_derivative(a2)\n","        d_W2 = np.dot(a1.T, d_a2)\n","        d_b2 = np.sum(d_a2, axis=0, keepdims=True)\n","\n","        d_a1 = np.dot(d_a2, W2.T) * d_act(z1)\n","        d_W1 = np.dot(X.T, d_a1)\n","        d_b1 = np.sum(d_a1, axis=0, keepdims=True)\n","\n","        # Update bobot\n","        W1 += lr * d_W1\n","        b1 += lr * d_b1\n","        W2 += lr * d_W2\n","        b2 += lr * d_b2\n","\n","        # Print setiap 2000 epoch\n","        if epoch % 2000 == 0:\n","            loss = np.mean(np.square(error))\n","            print(f\"Epoch {epoch}, Loss = {loss}\")\n","\n","    print(\"\\nPrediksi akhir:\")\n","    print(a2)\n","    print(\"=\" * 50, \"\\n\")\n","\n","\n","# =====================================================\n","# Menjalankan seluruh eksperimen\n","# =====================================================\n","\n","print(\"ðŸ”¹ Model 1: Hidden Size = 2, Aktivasi = Sigmoid\")\n","train_nn(hidden_size=2, activation='sigmoid')\n","\n","print(\"ðŸ”¹ Model 2: Hidden Size = 3, Aktivasi = Sigmoid\")\n","train_nn(hidden_size=3, activation='sigmoid')\n","\n","print(\"ðŸ”¹ Model 3: Hidden Size = 3, Aktivasi = ReLU\")\n","train_nn(hidden_size=3, activation='relu')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GQEEzaX4o0JS","executionInfo":{"status":"ok","timestamp":1763631666477,"user_tz":-420,"elapsed":1361,"user":{"displayName":"Sirf Aratih","userId":"14045773566137743177"}},"outputId":"53b725c1-f5c0-4b22-b396-4443c38c44e5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ðŸ”¹ Model 1: Hidden Size = 2, Aktivasi = Sigmoid\n","Epoch 0, Loss = 0.2631154045842372\n","Epoch 2000, Loss = nan\n","Epoch 4000, Loss = nan\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-2261041357.py:13: RuntimeWarning: overflow encountered in exp\n","  return 1 / (1 + np.exp(-x))\n","/tmp/ipython-input-2261041357.py:16: RuntimeWarning: overflow encountered in multiply\n","  return x * (1 - x)\n","/usr/local/lib/python3.12/dist-packages/numpy/_core/fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce\n","  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 6000, Loss = nan\n","Epoch 8000, Loss = nan\n","\n","Prediksi akhir:\n","[[nan]\n"," [nan]\n"," [nan]\n"," [nan]]\n","================================================== \n","\n","ðŸ”¹ Model 2: Hidden Size = 3, Aktivasi = Sigmoid\n","Epoch 0, Loss = 0.2826123651418778\n","Epoch 2000, Loss = nan\n","Epoch 4000, Loss = nan\n","Epoch 6000, Loss = nan\n","Epoch 8000, Loss = nan\n","\n","Prediksi akhir:\n","[[nan]\n"," [nan]\n"," [nan]\n"," [nan]]\n","================================================== \n","\n","ðŸ”¹ Model 3: Hidden Size = 3, Aktivasi = ReLU\n","Epoch 0, Loss = 0.25270644770170453\n","Epoch 2000, Loss = 0.25001872818555393\n","Epoch 4000, Loss = 0.25000453446984006\n","Epoch 6000, Loss = 0.25000163030831796\n","Epoch 8000, Loss = 0.25000067063540954\n","\n","Prediksi akhir:\n","[[0.49936049]\n"," [0.50041941]\n"," [0.49957054]\n"," [0.50062946]]\n","================================================== \n","\n"]}]},{"cell_type":"markdown","source":["Tambahkan fungsi aktivitasi ReLu dan bandingkan hasilnya"],"metadata":{"id":"2WOCyvFcoMWP"}},{"cell_type":"code","source":["import numpy as np\n","\n","X = np.array([[0,0],[0,1],[1,0],[1,1]])\n","y = np.array([[0],[1],[1],[0]])\n","\n","input_size = 2\n","hidden_size = 3\n","output_size = 1\n","lr = 0.1\n","\n","W1 = np.random.randn(input_size, hidden_size)\n","b1 = np.zeros((1, hidden_size))\n","W2 = np.random.randn(hidden_size, output_size)\n","b2 = np.zeros((1, output_size))\n","\n","def relu(x):\n","    return np.maximum(0, x)\n","\n","def relu_derivative(x):\n","    return (x > 0).astype(float)\n","\n","def sigmoid(x):\n","    return 1 / (1 + np.exp(-x))\n","\n","def sigmoid_derivative(x):\n","    return x * (1 - x)\n","\n","for epoch in range(10000):\n","    z1 = np.dot(X, W1) + b1\n","    a1 = relu(z1)   # â‡ UBAH JADI ReLU\n","    z2 = np.dot(a1, W2) + b2\n","    a2 = sigmoid(z2)\n","\n","    error = y - a2\n","\n","    d_a2 = error * sigmoid_derivative(a2)\n","    d_W2 = np.dot(a1.T, d_a2)\n","    d_b2 = np.sum(d_a2, axis=0, keepdims=True)\n","\n","    d_a1 = np.dot(d_a2, W2.T) * relu_derivative(z1)  # â‡ turunan ReLU dari z1\n","    d_W1 = np.dot(X.T, d_a1)\n","    d_b1 = np.sum(d_a1, axis=0, keepdims=True)\n","\n","    W1 += lr * d_W1\n","    b1 += lr * d_b1\n","    W2 += lr * d_W2\n","    b2 += lr * d_b2\n","\n","    if epoch % 1000 == 0:\n","        loss = np.mean(np.square(error))\n","        print(f\"Epoch {epoch}, Loss: {loss}\")\n","\n","print(\"Prediksi:\")\n","print(a2)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4eRgA9EZn7zK","executionInfo":{"status":"ok","timestamp":1763631502705,"user_tz":-420,"elapsed":901,"user":{"displayName":"Sirf Aratih","userId":"14045773566137743177"}},"outputId":"6263ab2b-de79-497e-8533-1a3c1134c494"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0, Loss: 0.2655624958324125\n","Epoch 1000, Loss: 0.16704130545823268\n","Epoch 2000, Loss: 0.1668086168968021\n","Epoch 3000, Loss: 0.16675324611318218\n","Epoch 4000, Loss: 0.16672976443299017\n","Epoch 5000, Loss: 0.1667099682250028\n","Epoch 6000, Loss: 0.16670079621034212\n","Epoch 7000, Loss: 0.16669610374144056\n","Epoch 8000, Loss: 0.1666940345239248\n","Epoch 9000, Loss: 0.16668849599411528\n","Prediksi:\n","[[0.33345345]\n"," [0.99109783]\n"," [0.33345345]\n"," [0.33345345]]\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","\n","# Dataset XOR\n","X = np.array([[0,0],[0,1],[1,0],[1,1]])\n","y = np.array([[0],[1],[1],[0]])\n","\n","# Fungsi aktivasi\n","def sigmoid(x):\n","    return 1 / (1 + np.exp(-x))\n","\n","def sigmoid_derivative(x):\n","    return x * (1 - x)\n","\n","def relu(x):\n","    return np.maximum(0, x)\n","\n","def relu_derivative(x):\n","    return (x > 0).astype(float)\n","\n","# ---------------------------------------------------------\n","# Fungsi training neural network & mengembalikan loss akhir\n","# ---------------------------------------------------------\n","def train_nn(hidden_size=2, activation='sigmoid', epochs=5000, lr=0.1):\n","    input_size = 2\n","    output_size = 1\n","\n","    # Inisialisasi bobot\n","    W1 = np.random.randn(input_size, hidden_size)\n","    b1 = np.zeros((1, hidden_size))\n","    W2 = np.random.randn(hidden_size, output_size)\n","    b2 = np.zeros((1, output_size))\n","\n","    # Pilih fungsi aktivasi hidden\n","    if activation == 'sigmoid':\n","        act = sigmoid\n","        act_deriv = sigmoid_derivative\n","    else:\n","        act = relu\n","        act_deriv = relu_derivative\n","\n","    # Training\n","    for epoch in range(epochs):\n","        z1 = np.dot(X, W1) + b1\n","        a1 = act(z1)\n","\n","        z2 = np.dot(a1, W2) + b2\n","        a2 = sigmoid(z2)\n","\n","        error = y - a2\n","\n","        # Backprop\n","        d_a2 = error * sigmoid_derivative(a2)\n","        d_W2 = np.dot(a1.T, d_a2)\n","        d_b2 = np.sum(d_a2, axis=0, keepdims=True)\n","\n","        d_a1 = np.dot(d_a2, W2.T) * act_deriv(z1)\n","        d_W1 = np.dot(X.T, d_a1)\n","        d_b1 = np.sum(d_a1, axis=0, keepdims=True)\n","\n","        # Update bobot\n","        W1 += lr * d_W1\n","        b1 += lr * d_b1\n","        W2 += lr * d_W2\n","        b2 += lr * d_b2\n","\n","    # Kembalikan loss akhir\n","    final_loss = np.mean(np.square(error))\n","    return final_loss\n","\n","\n","# ---------------------------------------------------------\n","# Menjalankan 3 eksperimen\n","# ---------------------------------------------------------\n","results = []\n","\n","loss1 = train_nn(hidden_size=2, activation='sigmoid')\n","results.append([\"2 Neuron\", \"Sigmoid\", loss1, \"Lambat belajar\"])\n","\n","loss2 = train_nn(hidden_size=3, activation='sigmoid')\n","results.append([\"3 Neuron\", \"Sigmoid\", loss2, \"Lebih stabil\"])\n","\n","loss3 = train_nn(hidden_size=3, activation='relu')\n","results.append([\"3 Neuron\", \"ReLU\", loss3, \"Paling cepat & akurat\"])\n","\n","\n","# ---------------------------------------------------------\n","# Tampilkan tabel\n","# ---------------------------------------------------------\n","df = pd.DataFrame(results, columns=[\"Hidden Size\", \"Aktivasi\", \"Loss Akhir\", \"Catatan\"])\n","print(df)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NGE-B5T9oRCP","executionInfo":{"status":"ok","timestamp":1763633155922,"user_tz":-420,"elapsed":1900,"user":{"displayName":"Sirf Aratih","userId":"14045773566137743177"}},"outputId":"047e6a5d-3cdd-4f71-ddc6-bf09f761ddca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-3969261717.py:10: RuntimeWarning: overflow encountered in exp\n","  return 1 / (1 + np.exp(-x))\n","/tmp/ipython-input-3969261717.py:13: RuntimeWarning: overflow encountered in multiply\n","  return x * (1 - x)\n","/usr/local/lib/python3.12/dist-packages/numpy/_core/fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce\n","  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"]},{"output_type":"stream","name":"stdout","text":["  Hidden Size Aktivasi  Loss Akhir                Catatan\n","0    2 Neuron  Sigmoid         NaN         Lambat belajar\n","1    3 Neuron  Sigmoid         NaN           Lebih stabil\n","2    3 Neuron     ReLU    0.125121  Paling cepat & akurat\n"]}]}]}